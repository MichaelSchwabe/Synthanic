{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.model_selection\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from autoPyTorch import AutoNetClassification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "path = \"data/\"\n",
    "df_train = pd.read_csv(path+\"train_preprocess_binarized_hotEncoded_lite.csv\")\n",
    "df_test = pd.read_csv(path+\"test.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# data and metric imports\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train[\"Survived\"]\n",
    "del df_train[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_train, y, test_size = 0.25, random_state = 42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 10)\n",
      "(75000, 10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(X_train.shape)\n",
    "\n",
    "class BinaryClassification(torch.nn.Module):\n",
    "    def __init__(self, input_dimension):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(input_dimension, 1)\n",
    "\n",
    "    def forward(self, input_dimension):\n",
    "        return self.linear(input_dimension)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, input_dimension = X_train.shape\n",
    "\n",
    "model = torch.nn.Linear(input_dimension, 1)\n",
    "\n",
    "\"\"\"train the model\"\"\"\n",
    "\n",
    "def configure_loss_function(): \n",
    "    return torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "def configure_optimizer(model):\n",
    "    return torch.optim.Adam(model.parameters())\n",
    "\n",
    "def full_gd(model, criterion, optimizer, X_train, y_train, n_epochs=200000):\n",
    "    train_losses = np.zeros(n_epochs)\n",
    "    test_losses = np.zeros(n_epochs)\n",
    "\n",
    "    for it in range(n_epochs): \n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    outputs_test = model(X_test)\n",
    "    loss_test = criterion(outputs_test, y_test)\n",
    "\n",
    "    train_losses[it] = loss.item()\n",
    "    test_losses[it] = loss_test.item()\n",
    "\n",
    "    if (it + 1) % 50 == 0:\n",
    "        print(f'In this epoch {it+1}/{n_epochs}, Training loss: {loss.item():.4f}, Test loss: {loss_test.item():.4f}')\n",
    "\n",
    "    return train_losses, test_losses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this epoch 200000/200000, Training loss: 0.5041, Test loss: 0.5057\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7668266666666667\n",
      "0.76584\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32)).reshape(-1, 1)\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32)).reshape(-1, 1)\n",
    "\n",
    "criterion = configure_loss_function()\n",
    "optimizer = configure_optimizer(model)\n",
    "train_losses, test_losses = full_gd(model, criterion, optimizer, X_train, y_train)\n",
    "\n",
    "plt.plot(train_losses, label = 'train loss')\n",
    "plt.plot(test_losses, label = 'test loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\"\"\"evaluate model\"\"\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    p_train = model(X_train)\n",
    "    p_train = (p_train.numpy() > 0)\n",
    "\n",
    "    train_acc = np.mean(y_train.numpy() == p_train)\n",
    "\n",
    "    p_test = model(X_test)\n",
    "    p_test = (p_test.numpy() > 0)\n",
    "  \n",
    "    test_acc = np.mean(y_test.numpy() == p_test)\n",
    "\n",
    "print(train_acc)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Banknote authentication using PyTorch \n",
      "\n",
      "Creating train and test\n",
      "Creating 4-(8-8)-1 binary NN classifier \n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-136-2faf80a93331>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-136-2faf80a93331>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[1;31m# 2. create neural network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Creating 4-(8-8)-1 binary NN classifier \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m     \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[1;31m# 3. train network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\synthanic\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mto\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    671\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 673\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m     def register_backward_hook(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\synthanic\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    385\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\synthanic\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    407\u001b[0m                 \u001b[1;31m# `with torch.no_grad():`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 409\u001b[1;33m                     \u001b[0mparam_applied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    410\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\synthanic\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    669\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[0;32m    670\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[1;32m--> 671\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    672\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\synthanic\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    162\u001b[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001b[0;32m    163\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_cuda_getDeviceCount'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m             raise AssertionError(\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# banknote_bnn.py\n",
    "# Banknote classification\n",
    "# PyTorch 1.6.0-CPU Anaconda3-2020.02  Python 3.7.6\n",
    "# Windows 10 \n",
    "\n",
    "import numpy as np\n",
    "import torch as T\n",
    "device = T.device(\"cuda\")  # apply to Tensor or Module\n",
    "\n",
    "#        1         2         3         4         5         6\n",
    "# 3456789012345678901234567890123456789012345678901234567890\n",
    "# ----------------------------------------------------------\n",
    "# predictors and label in same file\n",
    "# archive.ics.uci.edu/ml/datasets/banknote+authentication\n",
    "# IDs 0001 to 1372 added\n",
    "# data has been k=20 normalized (all four columns)\n",
    "# ID  variance  skewness  kurtosis  entropy  class\n",
    "# [0]    [1]      [2]       [3]       [4]     [5]\n",
    "#  (0 = authentic, 1 = forgery)  # verified\n",
    "# train: 1097 items (80%), test: 275 item (20%)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def accuracy(model, ds):\n",
    "    # ds is a iterable Dataset of Tensors\n",
    "    n_correct = 0; n_wrong = 0\n",
    "\n",
    "    # alt: create DataLoader and then enumerate it\n",
    "    for i in range(len(ds)):\n",
    "        inpts = ds[i]['predictors']\n",
    "        target = ds[i]['target']    # float32  [0.0] or [1.0]\n",
    "        with T.no_grad():\n",
    "            oupt = model(inpts)\n",
    "\n",
    "        # avoid 'target == 1.0'\n",
    "        if target < 0.5 and oupt < 0.5:  # .item() not needed\n",
    "            n_correct += 1\n",
    "        elif target >= 0.5 and oupt >= 0.5:\n",
    "            n_correct += 1\n",
    "        else:\n",
    "            n_wrong += 1\n",
    "\n",
    "    return (n_correct * 1.0) / (n_correct + n_wrong)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def acc_coarse(model, ds):\n",
    "    inpts = ds[:]['predictors']  # all rows\n",
    "    targets = ds[:]['target']    # all target 0s and 1s\n",
    "    with T.no_grad():\n",
    "        oupts = model(inpts)         # all computed ouputs\n",
    "    pred_y = oupts >= 0.5        # tensor of 0s and 1s\n",
    "    num_correct = T.sum(targets==pred_y)\n",
    "    acc = (num_correct.item() * 1.0 / len(ds))  # scalar\n",
    "    return acc\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "def my_bce(model, batch):\n",
    "    # mean binary cross entropy error. somewhat slow\n",
    "    sum = 0.0\n",
    "    inpts = batch['predictors']\n",
    "    targets = batch['target']\n",
    "    with T.no_grad():\n",
    "        oupts = model(inpts)\n",
    "        for i in range(len(inpts)):\n",
    "            oupt = oupts[i]\n",
    "            # should prevent log(0) which is -infinity\n",
    "            if targets[i] >= 0.5:  # avoiding == 1.0\n",
    "                sum += T.log(oupt)\n",
    "            else:\n",
    "                sum += T.log(1 - oupt)\n",
    "\n",
    "            return -sum / len(inpts)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "class Net(T.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.hid1 = T.nn.Linear(10, 100)  # 4-(8-8)-1\n",
    "        self.hid2 = T.nn.Linear(100, 200)\n",
    "        self.oupt = T.nn.Linear(200, 1)\n",
    "\n",
    "        T.nn.init.xavier_uniform_(self.hid1.weight) \n",
    "        T.nn.init.zeros_(self.hid1.bias)\n",
    "        T.nn.init.xavier_uniform_(self.hid2.weight) \n",
    "        T.nn.init.zeros_(self.hid2.bias)\n",
    "        T.nn.init.xavier_uniform_(self.oupt.weight) \n",
    "        T.nn.init.zeros_(self.oupt.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = T.tanh(self.hid1(x)) \n",
    "        z = T.tanh(self.hid2(z))\n",
    "        z = T.sigmoid(self.oupt(z)) \n",
    "        return z\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "def main():\n",
    "  # 0. get started\n",
    "    print(\"\\nBanknote authentication using PyTorch \\n\")\n",
    "    T.manual_seed(1)\n",
    "    np.random.seed(1)\n",
    "\n",
    "    # 1. create Dataset and DataLoader objects\n",
    "    print(\"Creating train and test\")\n",
    "\n",
    "    #train_file = \".\\\\Data\\\\banknote_k20_train.txt\"\n",
    "    #test_file = \".\\\\Data\\\\banknote_k20_test.txt\"\n",
    "\n",
    "    train_ds = X_train  # all rows\n",
    "    test_ds = X_test\n",
    "\n",
    "    bat_size = 10\n",
    "    train_ldr = T.utils.data.DataLoader(train_ds,\n",
    "    batch_size=bat_size, shuffle=True)\n",
    "    # test_ldr = T.utils.data.DataLoader(test_ds,\n",
    "    #   batch_size=1, shuffle=False)  # not needed\n",
    "\n",
    "    # 2. create neural network\n",
    "    print(\"Creating 4-(8-8)-1 binary NN classifier \")\n",
    "    net = Net().to(device)\n",
    "\n",
    "    # 3. train network\n",
    "    print(\"\\nPreparing training\")\n",
    "    net = net.train()  # set training mode\n",
    "    lrn_rate = 0.01\n",
    "    loss_obj = T.nn.BCELoss()  # binary cross entropy\n",
    "    optimizer = T.optim.SGD(net.parameters(),\n",
    "    lr=lrn_rate)\n",
    "    max_epochs = 100\n",
    "    ep_log_interval = 10\n",
    "    print(\"Loss function: \" + str(loss_obj))\n",
    "    print(\"Optimizer: SGD\")\n",
    "    print(\"Learn rate: 0.01\")\n",
    "    print(\"Batch size: 10\")\n",
    "    print(\"Max epochs: \" + str(max_epochs))\n",
    "\n",
    "    print(\"\\nStarting training\")\n",
    "    for epoch in range(0, max_epochs):\n",
    "        epoch_loss = 0.0            # for one full epoch\n",
    "        epoch_loss_custom = 0.0\n",
    "        num_lines_read = 0\n",
    "\n",
    "    for (batch_idx, batch) in enumerate(train_ldr):\n",
    "        X = batch['predictors']  # [10,4]  inputs\n",
    "        Y = batch['target']      # [10,1]  targets\n",
    "        oupt = net(X)            # [10,1]  computeds \n",
    "\n",
    "        loss_val = loss_obj(oupt, Y)   # a tensor\n",
    "        epoch_loss += loss_val.item()  # accumulate\n",
    "        # epoch_loss += loss_val  # is OK\n",
    "        # epoch_loss_custom += my_bce(net, batch)\n",
    "\n",
    "        optimizer.zero_grad() # reset all gradients\n",
    "        loss_val.backward()   # compute all gradients\n",
    "        optimizer.step()      # update all weights\n",
    "\n",
    "    if epoch % ep_log_interval == 0:\n",
    "        print(\"epoch = %4d   loss = %0.4f\" % \\\n",
    "        (epoch, epoch_loss))\n",
    "      # print(\"custom loss = %0.4f\" % epoch_loss_custom)\n",
    "      # print(\"\")\n",
    "    print(\"Done \")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "  # 4. evaluate model\n",
    "    net = net.eval()\n",
    "    acc_train = accuracy(net, train_ds)\n",
    "    print(\"\\nAccuracy on train data = %0.2f%%\" % \\\n",
    "        (acc_train * 100))\n",
    "    acc_test = accuracy(net, test_ds)\n",
    "    print(\"Accuracy on test data = %0.2f%%\" % \\\n",
    "        (acc_test * 100))\n",
    "\n",
    "  # acc_train_c = acc_coarse(net, train_ds)\n",
    "  # print(\"Accuracy on train data = %0.2f%%\" % \\\n",
    "  #  (acc_train_c * 100))\n",
    "  # acc_test_c = acc_coarse(net, test_ds)\n",
    "  # print(\"Accuracy on test data = %0.2f%%\" % \\\n",
    "  #  (acc_test_c * 100))\n",
    "\n",
    "    # 5. save model\n",
    "    print(\"\\nSaving trained model state_dict \\n\")\n",
    "    path = \".\\\\Models\\\\banknote_sd_model.pth\"\n",
    "    T.save(net.state_dict(), path)\n",
    "\n",
    "    # print(\"\\nSaving entire model \\n\")\n",
    "    # path = \".\\\\Models\\\\banknote_full_model.pth\"\n",
    "    # T.save(net, path\n",
    "\n",
    "    # print(\"\\nSaving trained model as ONNX \\n\")\n",
    "    # path = \".\\\\Models\\\\banknote_onnx_model.onnx\"\n",
    "    # dummy = T.tensor([[0.5, 0.5, 0.5, 0.5]],\n",
    "    #   dtype=T.float32).to(device)\n",
    "    # T.onnx.export(net, dummy, path,\n",
    "    #   input_names=[\"input1\"],\n",
    "    #  output_names=[\"output1\"])\n",
    "\n",
    "    # model = Net()  # later . . \n",
    "    # model.load_state_dict(T.load(path))\n",
    "\n",
    "    # 6. make a prediction \n",
    "    raw_inpt = np.array([[4.4, 1.8, -5.6, 3.2]],\n",
    "    dtype=np.float32)\n",
    "    norm_inpt = raw_inpt / 20\n",
    "    unknown = T.tensor(norm_inpt,\n",
    "    dtype=T.float32).to(device) \n",
    "\n",
    "    print(\"Setting normalized inputs to:\")\n",
    "    for x in unknown[0]:\n",
    "        print(\"%0.3f \" % x, end=\"\")\n",
    "\n",
    "    net = net.eval()\n",
    "    with T.no_grad():\n",
    "        raw_out = net(unknown)    # a Tensor\n",
    "    pred_prob = raw_out.item()  # scalar, [0.0, 1.0]\n",
    "\n",
    "    print(\"\\nPrediction prob = %0.6f \" % pred_prob)\n",
    "    if pred_prob < 0.5:\n",
    "        print(\"Prediction = authentic\")\n",
    "    else:\n",
    "        print(\"Prediction = forgery\")\n",
    "\n",
    "    print(\"\\nEnd Banknote demo\")\n",
    "\n",
    "if __name__== \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "current_device() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-144-b94cdfd074ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: current_device() takes 0 positional arguments but 1 was given"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
